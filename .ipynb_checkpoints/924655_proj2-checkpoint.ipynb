{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xiaoyue Lin, 924655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The training-evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    '''This pre-processing function makes a review text case-insensitive, removes punctuation,\n",
    "    removes stop words, removes single characters, lemmatizes words.'''\n",
    "\n",
    "    # convert reviews to lower case\n",
    "    reviews = reviews.str.lower()\n",
    "\n",
    "    # initialize lemmatizer and a list of stopwords\n",
    "    lemmatizer = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "    all_stopwords = lemmatizer.Defaults.stop_words\n",
    "    \n",
    "    for i in range(len(reviews)):\n",
    "        rev = reviews[i]\n",
    "        # remove punctuations and numbers\n",
    "        symbols = \",!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~0123456789\"\n",
    "        for sym in symbols:\n",
    "            rev = np.char.replace(rev, sym, ' ')\n",
    "\n",
    "        # remove stop words and single characters\n",
    "        rev_tokens = word_tokenize(str(rev))\n",
    "        tokens_without_sw = \" \".join([word for word in rev_tokens if (word not in all_stopwords) and (len(word) > 1)])\n",
    "\n",
    "        # remove ’\n",
    "        tokens_without_sw = np.char.replace(tokens_without_sw, \"'\", ' ')\n",
    "        \n",
    "        # spaCy Lemmatization\n",
    "        doc = lemmatizer(str(tokens_without_sw))\n",
    "        reviews[i] = \" \".join([token.lemma_ for token in doc]) # Extract the lemma for each token and join\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cm(y_true, y_pred, title):\n",
    "    '''This function draws a confusion matrix'''\n",
    "    cm = confusion_matrix(y_true, y_pred, labels = [1, 3, 5], normalize = 'true')\n",
    "    df_cm = pd.DataFrame(cm, columns=['Negative', 'Neutral', 'Postive'], index = ['Negative', 'Neutral', 'Postive'])\n",
    "    df_cm.index.name = 'Actual rating'\n",
    "    df_cm.columns.name = 'Predicted rating'\n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title(title)\n",
    "    sn.heatmap(df_cm, annot = True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of training instances:  28068\n",
      "num of distinct words in training： 41648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load in data\n",
    "\n",
    "train_review_table = pd.read_csv(r\"review_text_train.csv\", index_col = False, delimiter = ',',\n",
    "                                 header = 0)\n",
    "train_corpus = train_review_table['review']  # instances\n",
    "print('num of training instances: ', len(train_corpus))\n",
    "vocab = pickle.load(open(r\".\\review_text_features_countvec\\train_countvectorizer.pkl\", \"rb\"))\n",
    "vocab_dict = vocab.vocabulary_ # access the list of vocabulary\n",
    "print(\"num of distinct words in training：\", len(vocab_dict)) # num of distinct words in training ins\n",
    "\n",
    "train_meta_table = pd.read_csv(r\"review_meta_train.csv\", index_col = False, header = 0)\n",
    "ratings = train_meta_table['rating']\n",
    "votes = train_meta_table[['vote_funny', 'vote_cool', 'vote_useful']]\n",
    "\n",
    "test_review_table = pd.read_csv(r\"review_text_test.csv\", index_col = False, delimiter = ',', header = 0)\n",
    "X_test_reviews = test_review_table['review']\n",
    "test_meta_table = pd.read_csv(r\"review_meta_test.csv\", index_col = False, header = 0)\n",
    "votes_test = test_meta_table[['vote_funny', 'vote_cool', 'vote_useful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2336, 5: 19288, 3: 6444})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ratings) # counting each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "train_corpus_tidy = preprocess(train_corpus)\n",
    "text_corpus_tidy = preprocess(X_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_tidy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, ks, X_train, votes_train, y_train, X_valid, votes_valid, y_valid, ngrams, print_feat):\n",
    "    '''This function trains and tests model.'''\n",
    "    \n",
    "    n_ks = len(ks)\n",
    "    \n",
    "    # Vectorizing data\n",
    "    vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                                 lowercase = True,  ngram_range = ngrams)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    #print(\"number of distinct words in training set after preprocessing:\", X_train_vec.shape[1])\n",
    "    X_valid_vec = vectorizer.transform(X_valid)\n",
    "    #print(X_valid_vec.shape)\n",
    "\n",
    "    # Chi-square feature selection\n",
    "    Xs = [] # a set of training and validation pairs\n",
    "    vec_0_ind_ks = [] # indices of zero vectors\n",
    "    y_valid_pred1_ks = []\n",
    "    for k in ks:\n",
    "        if k != 'complete':\n",
    "            chisq = SelectKBest(chi2, k = k)\n",
    "            X_train_selected = chisq.fit_transform(X_train_vec, y_train)\n",
    "            X_valid_selected = chisq.transform(X_valid_vec)\n",
    "        else:\n",
    "            X_train_selected = X_train_vec # selection is skipped if all features are required\n",
    "            X_valid_selected = X_valid_vec\n",
    "            \n",
    "        n_valid = X_valid_selected .shape[0]\n",
    "        vec_0_ind = [] # indices of zero vectors\n",
    "        n_zero_vec = 0  # num of zero vectors\n",
    "        for i in range(n_valid):\n",
    "            if X_valid_selected[i - n_zero_vec].sum(axis = 1) == 0:\n",
    "                X_valid_selected = vstack(\n",
    "                    [X_valid_selected[:(i - n_zero_vec), :], X_valid_selected[(i - n_zero_vec) + 1:, :]])\n",
    "                vec_0_ind.append(X_valid.index[i])\n",
    "                n_zero_vec += 1\n",
    "        #print('\\nnumber of zero vec: ', n_zero_vec, '\\n')\n",
    "        vec_0_ind_ks.append(vec_0_ind)\n",
    "        \n",
    "        # save training and validation pairs\n",
    "        X = (X_train_selected, X_valid_selected)\n",
    "        Xs.append(X)\n",
    "\n",
    "        # predict zero vectors based on votes\n",
    "        y_valid_pred1 = []\n",
    "        if vec_0_ind:\n",
    "            clf_vote = MultinomialNB()\n",
    "            clf_vote.fit(votes_train, y_train)\n",
    "            y_valid_pred1 = clf_vote.predict(votes_valid.ix[vec_0_ind])\n",
    "            y_valid_pred1_ks.append(y_valid_pred1)\n",
    "\n",
    "        # print a sample of selected feature if print_feat is True\n",
    "        if print_feat:\n",
    "            for feat_num in chisq.get_support(indices = True):\n",
    "                print(\n",
    "                    vectorizer.get_feature_names()[feat_num])\n",
    "            print_feat = False\n",
    "\n",
    "    Xs_names = ['chi-square with k = ' + str(k) for k in ks]\n",
    "    \n",
    "    # test performance on validation\n",
    "    accuracies = []\n",
    "    for n in range(n_ks):\n",
    "        X_train_t, X_test_t = Xs[n]\n",
    "        model.fit(X_train_t, y_train)\n",
    "        y_valid_pred2 = model.predict(X_test_t)\n",
    "\n",
    "        # combine two lists of predicted labels\n",
    "        for j in range(len(vec_0_ind_ks[n])):\n",
    "            ind_valid = vec_0_ind_ks[n][j]\n",
    "            pred_valid = y_valid_pred1_ks[n][j]\n",
    "            ind_cls = 0 # order in predicted class\n",
    "            for ind in X_valid.index:\n",
    "                if ind == ind_valid:\n",
    "                    y_valid_pred2 = np.insert(y_valid_pred2, ind_cls, pred_valid)\n",
    "                ind_cls += 1\n",
    "        \n",
    "        # if y_valid is None, this is classifying the test set; else, calculate the accuracy\n",
    "        if any(y_valid):        \n",
    "            acc = accuracy_score(y_true = y_valid, y_pred = y_valid_pred2)\n",
    "            print(Xs_names[n], acc)\n",
    "            accuracies.append(acc)\n",
    "\n",
    "    return accuracies, y_valid_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "\n",
    "kFolds = 5\n",
    "skf = StratifiedKFold(kFolds, shuffle = True, random_state = 7)  # todo try diff rand_state\n",
    "X_train_folds = []\n",
    "votes_train_folds = []\n",
    "y_train_folds = []\n",
    "X_valid_folds = []\n",
    "votes_valid_folds = []\n",
    "y_valid_folds = []\n",
    "for train_index, test_index in skf.split(X = train_corpus_tidy, y = ratings):\n",
    "    X_train_folds.append(train_corpus_tidy[train_index])\n",
    "    votes_train_folds.append(votes.iloc[train_index, :])\n",
    "    y_train_folds.append(ratings[train_index])\n",
    "    X_valid_folds.append(train_corpus_tidy[test_index])\n",
    "    votes_valid_folds.append(votes.iloc[test_index, :])\n",
    "    y_valid_folds.append(ratings[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning k on MNB_(1, 1)\n",
    "\n",
    "ks = [1000, 2000, 5000, 10000, 20000, 25000, 30000, 'complete']\n",
    "n_ks = len(ks)\n",
    "accuracies = np.zeros(n_ks)  \n",
    "for f in range(kFolds):\n",
    "    acc, y_pred = train_test(MultinomialNB(), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 1), print_feat = False)\n",
    "    for k in range(n_ks):\n",
    "        accuracies[k] += acc[k] / kFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies # mnb_(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuning k on MNB_(1, 2)\n",
    "\n",
    "ks = [1000, 2000, 5000, 10000, 20000, 25000, 30000, 'complete']\n",
    "n_ks = len(ks)\n",
    "accuracies = np.zeros(n_ks)  \n",
    "for f in range(kFolds):\n",
    "    acc, y_pred = train_test(MultinomialNB(), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 2), print_feat = False)\n",
    "    for k in range(n_ks):\n",
    "        accuracies[k] += acc[k] / kFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies # mnb_(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnb_(1, 1)\n",
    "# tune the k to the optimal value = 25000\n",
    "ks = [25000]\n",
    "f = 0 # fold index\n",
    "acc, y_pred = train_test(MultinomialNB(), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 1), print_feat = False)\n",
    "\n",
    "draw_cm(y_valid_folds[f], y_pred, 'MNB_(1, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnb_(1, 2)\n",
    "# tune the k to the optimal value = 20000\n",
    "ks = [20000]\n",
    "f = 0\n",
    "acc, y_pred = train_test(MultinomialNB(), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 2), print_feat = False)\n",
    "\n",
    "draw_cm(y_valid_folds[f], y_pred, 'MNB_(1, 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuning k on lgr_(1, 1)\n",
    "ks = [1000, 2000, 5000, 10000, 20000, 25000, 30000, 'complete']\n",
    "n_ks = len(ks)\n",
    "accuracies = np.zeros(n_ks)  \n",
    "for f in range(kFolds):\n",
    "    acc, y_pred = train_test(LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 1), print_feat = False)\n",
    "    for k in range(n_ks):\n",
    "        accuracies[k] += acc[k] / kFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies # lgr_(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning k on lgr_(1, 2)\n",
    "ks = [1000, 2000, 5000, 10000, 20000, 25000, 30000, 'complete']\n",
    "n_ks = len(ks)\n",
    "accuracies = np.zeros(n_ks)  \n",
    "for f in range(kFolds):\n",
    "    acc, y_pred = train_test(LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000), ks, X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 2), print_feat = False)\n",
    "    for k in range(n_ks):\n",
    "        accuracies[k] += acc[k] / kFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies # lgr_1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgr_(1, 1)\n",
    "# tune the k to the optimal value = 2000\n",
    "\n",
    "ks = [2000]\n",
    "f = 0\n",
    "acc, y_pred = train_test(LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000), ks, \n",
    "                         X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 1), print_feat = False)\n",
    "\n",
    "draw_cm(y_valid_folds[f], y_pred, 'LGR _(1, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lgr\n",
    "# tune the k to the optimal value = 'complete'\n",
    "\n",
    "ks = ['complete']\n",
    "f = 0\n",
    "acc, y_pred = train_test(LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000), ks, \n",
    "                         X_train_folds[f], votes_train_folds[f], y_train_folds[f], \n",
    "                     X_valid_folds[f], votes_valid_folds[f], y_valid_folds[f], ngrams = (1, 2), print_feat = False)\n",
    "\n",
    "draw_cm(y_valid_folds[f], y_pred, 'LGR_(1, 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_csv = False # turning csv output on/off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classlabel of the test set\n",
    "# using mnb_(1, 1), k = 25000\n",
    "if get_csv:\n",
    "    final_model = MultinomialNB()\n",
    "    ks = [25000]\n",
    "    acc, y_pred = train_test(final_model, ks, train_corpus_tidy, votes, ratings, text_corpus_tidy, \n",
    "                             votes_test, [], ngrams = (1, 1), print_feat = False)\n",
    "    fname = \"mnb_(1,1)_25000.csv\"\n",
    "    pd.DataFrame({'Instance_id': np.arange(1, 7019), 'rating': y_pred}).to_csv(fname, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classlabel of the test set\n",
    "# using mnb_(1, 2), k = 20000\n",
    "\n",
    "if get_csv:\n",
    "    final_model = MultinomialNB()\n",
    "    ks = [20000]\n",
    "    acc, y_pred = train_test(final_model, ks, train_corpus_tidy, votes,\n",
    "               ratings, text_corpus_tidy, votes_test, [], ngrams = (1, 2), print_feat = False)\n",
    "    fname = \"mnb_(1,2)_20000.csv\"\n",
    "    pd.DataFrame({'Instance_id': np.arange(1, 7019), 'rating': y_pred}).to_csv(fname, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classlabel of the test set\n",
    "# using lgr_(1, 1), k = '2000'\n",
    "\n",
    "if get_csv:\n",
    "    final_model = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000)\n",
    "    ks = [2000]\n",
    "    acc, y_pred = train_test(final_model, ks, train_corpus_tidy, votes,\n",
    "               ratings, text_corpus_tidy, votes_test, [], ngrams = (1, 1), print_feat = False)\n",
    "    fname = \"lgr_(1,1)_2000.csv\"\n",
    "    pd.DataFrame({'Instance_id': np.arange(1, 7019), 'rating': y_pred}).to_csv(fname, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classlabel of the test set\n",
    "# using lgr_(1, 2), k = 'complete'\n",
    "\n",
    "if get_csv:\n",
    "    final_model = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter=1000)\n",
    "    ks = ['complete']\n",
    "    acc, y_pred = train_test(final_model, ks, train_corpus_tidy, votes,\n",
    "               ratings, text_corpus_tidy, votes_test, [], ngrams = (1, 2), print_feat = False)\n",
    "    fname = \"lgr_(1,2)_complete.csv\"\n",
    "    pd.DataFrame({'Instance_id': np.arange(1, 7019), 'rating': y_pred}).to_csv(fname, index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
